{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc68d30f",
   "metadata": {},
   "source": [
    "## 1.Perform combined over and undersampling on the diabetes dataset (use SMOTEENN). Explain how combined sampling works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dfd3e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "diabetes_df = pd.read_csv('../week-14-repository/diabetes.csv')\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bad6b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the class ratio \n",
    "#calculating the number of data that belong to each class in Outcome variable\n",
    "diabetes_df['Outcome'].value_counts()\n",
    "\n",
    "\n",
    "#The data is pretty imbalanced, where the majority class belongs to the “0” ( negative) \n",
    "# and the minority class belongs to the “1” (positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0110fdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Deciding independent(X) and depencdent(y) variables:\n",
    "X = diabetes_df.drop('Outcome',axis=1)\n",
    "y = diabetes_df['Outcome']\n",
    "\n",
    "#Splitting train and test \n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.5,random_state = 10)\n",
    "\n",
    "#Standardize \n",
    "sc = StandardScaler()\n",
    "X_train_scaler = sc.fit_transform(X_train)\n",
    "X_test_scaler = sc.fit_transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530c8e18",
   "metadata": {},
   "source": [
    "## Without using Smote-enn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00950d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance without Smote-enn is : 0.7838541666666666\n"
     ]
    }
   ],
   "source": [
    "#Checking the model performance without usiing Smote-enn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaler,y_train)\n",
    "y_pred = model.predict(X_test_scaler)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score=accuracy_score(y_test,y_pred)\n",
    "print(\"Model performance without Smote-enn is :\",accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1da7b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.80      0.84       280\n",
      "           1       0.58      0.74      0.65       104\n",
      "\n",
      "    accuracy                           0.78       384\n",
      "   macro avg       0.74      0.77      0.75       384\n",
      "weighted avg       0.81      0.78      0.79       384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Generating classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792477c4",
   "metadata": {},
   "source": [
    "## With SMOTE-ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a35d2329",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the accuracy score is pretty high, but the recall score is slightly lower (around 0.74). \n",
    "#This means that the model performance to correctly predict the minority class label is not good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a5cc3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "#this method combines the SMOTE ability to generate synthetic examples for minority class and ENN ability to delete \n",
    "#some observations from both classes that are identified as having different class between the observation’s class and \n",
    "#its K-nearest neighbor majority class.\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "smote_enn = SMOTEENN (random_state=42)\n",
    "X_resampled,y_resampled =smote_enn.fit_resample(X_train_scaler,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37b73fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance with Smote-enn is : 0.735793667435521\n"
     ]
    }
   ],
   "source": [
    "#train using resampled data\n",
    "\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_resampled,y_resampled)\n",
    "y_pred = model.predict(X_test_scaler)\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "balanced_acc_score=balanced_accuracy_score(y_test,y_pred)\n",
    "\n",
    "print(\"Model performance with Smote-enn is :\",balanced_acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f16f0f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.88      0.63      0.84      0.73      0.73      0.52       251\n",
      "          1       0.55      0.84      0.63      0.66      0.73      0.54       133\n",
      "\n",
      "avg / total       0.77      0.70      0.77      0.71      0.73      0.53       384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb62f6c6",
   "metadata": {},
   "source": [
    "The recall score after using smote-enn has increased, although the accuracy and precision score are slightly decreased. \n",
    "This means that the model performance to correctly predict the minority class label is getting better by\n",
    "using SMOTE-ENN to balance the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b8caa5",
   "metadata": {},
   "source": [
    "## 2.Comment on the performance of combined sampling vs the other approaches we have used for the diabetes dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bb42e3",
   "metadata": {},
   "source": [
    "## With SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "30d13a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7268518518518519"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = diabetes_df.drop('Outcome',axis = 1)\n",
    "y = diabetes_df['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "#Standardize\n",
    "sc = StandardScaler()\n",
    "X_train_scaler = sc.fit_transform(X_train)\n",
    "X_test_scaler = sc.fit_transform(X_test)\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = sm.fit_resample(X_train_scaler, y_train)\n",
    "\n",
    "#train using the resampled data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_resampled, y_resampled)\n",
    "\n",
    "#calculate the accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "y_pred = model.predict(X_test_scaler)\n",
    "balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64949298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.83      0.77      0.70      0.80      0.74      0.54       251\n",
      "          1       0.62      0.70      0.77      0.66      0.74      0.54       133\n",
      "\n",
      "avg / total       0.76      0.75      0.72      0.75      0.74      0.54       384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7dab4f",
   "metadata": {},
   "source": [
    "In my opinion,The performance of the combined sampling is slightly higher than the SMOTE and other techniques that swe have used so far for our diabetes dataset.\n",
    "SMOTE -ENN technique is the best in predicting the minority label in a better way as we have a good recall value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a51ed1",
   "metadata": {},
   "source": [
    "## 3.What is outlier detection? Why is it useful? What methods can you use for outlier detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bfc511",
   "metadata": {},
   "source": [
    "Overview:\n",
    "\n",
    "An outlier can be considered as an odd man out in a series of data. Outliers can be unusually and extremely different from most of the data points existing in our sample. It could be a very large observation or a very small observation. Outliers can create biased results while calculating the stats of the data due to its extreme nature, thereby affecting further statistical/ML models.\n",
    "Outlier detection is the process of detecting and subsequently excluding outliers from a given set of data.\n",
    "\n",
    "Methods for Outlier Detection :\n",
    "1) The simplest way to detect an outlier is by graphing the features or the data points. Visualization is one of the best and easiest ways to have an inference about the overall data and the outliers. Scatter plots and box plots are the most preferred visualization tools to detect outliers.\n",
    "\n",
    "2) Histograms can also be used to identify outlier. However in a histogram, existence of outliers can be detected by isolated bars.\n",
    "\n",
    "3) InterQuartile range (IQR) technique: This method can be used to find the maximum and minimum values of data points that are outliers by calculating the boundaries.\n",
    "\n",
    "\n",
    "4) Z score is an important concept in statistics. Z score is also called standard score. This score helps to understand if a data value is greater or smaller than mean and how far away it is from the mean. More specifically, Z score tells how many standard deviations away a data point is from the mean.\n",
    "\n",
    "    Z score = (x -mean) / std. deviation \n",
    "    \n",
    "    \n",
    "Z score and Outliers:\n",
    "If the z score of a data point is more than 3, it indicates that the data point is quite different from the other data points. Such a data point can be an outlier.\n",
    "data = [1, 2, 2, 2, 3, 1, 1, 15, 2, 2, 2, 3, 1, 1, 2]\n",
    "mean = np.mean(data)\n",
    "std = np.std(data)\n",
    "print('mean of the dataset is', mean)\n",
    "print('std. deviation is', std)\n",
    "\n",
    "\n",
    "threshold = 3\n",
    "outlier = []\n",
    "for i in data:\n",
    "    z = (i-mean)/std\n",
    "    if z > threshold:\n",
    "        outlier.append(i)\n",
    "print('outlier in dataset is', outlier)\n",
    "\n",
    "\n",
    "5) There are various statistical tests that can be performed to detect outliers and one of them is the hypothesis testing. Below three statistical tests use the concept of hypothesis testing to identify outliers.\n",
    " o Grubbs’ test\n",
    " o Chi –square test.\n",
    " o Dixon’s Q test.\n",
    " \n",
    " \n",
    "In Grubbs’ test and Dixon’s Q test, it is assumed that the data on which we are going to find outliers is normally distributed.\n",
    "Whereas Chi-square test can be used for the same with the chi-square distribution\n",
    "Dixon’s Q test are generally applied for datasets or samples containing very few observations and hence rarely used in data science."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14396583",
   "metadata": {},
   "source": [
    "## 4.\tPerform a linear SVM to predict credit approval (last column) using this dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b548c17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22.08</td>\n",
       "      <td>11.460</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>22.67</td>\n",
       "      <td>7.000</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>29.58</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>21.67</td>\n",
       "      <td>11.500</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.17</td>\n",
       "      <td>8.170</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.960</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>1</td>\n",
       "      <td>31.57</td>\n",
       "      <td>10.500</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>6.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1</td>\n",
       "      <td>20.67</td>\n",
       "      <td>0.415</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>0</td>\n",
       "      <td>18.83</td>\n",
       "      <td>9.540</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0</td>\n",
       "      <td>27.42</td>\n",
       "      <td>14.500</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>3.085</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>1</td>\n",
       "      <td>41.00</td>\n",
       "      <td>0.040</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A1     A2      A3  A4  A5  A6     A7  A8  A9  A10  A11  A12  A13   A14  \\\n",
       "0     1  22.08  11.460   2   4   4  1.585   0   0    0    1    2  100  1213   \n",
       "1     0  22.67   7.000   2   8   4  0.165   0   0    0    0    2  160     1   \n",
       "2     0  29.58   1.750   1   4   4  1.250   0   0    0    1    2  280     1   \n",
       "3     0  21.67  11.500   1   5   3  0.000   1   1   11    1    2    0     1   \n",
       "4     1  20.17   8.170   2   6   4  1.960   1   1   14    0    2   60   159   \n",
       "..   ..    ...     ...  ..  ..  ..    ...  ..  ..  ...  ...  ...  ...   ...   \n",
       "685   1  31.57  10.500   2  14   4  6.500   1   0    0    0    2    0     1   \n",
       "686   1  20.67   0.415   2   8   4  0.125   0   0    0    0    2    0    45   \n",
       "687   0  18.83   9.540   2   6   4  0.085   1   0    0    0    2  100     1   \n",
       "688   0  27.42  14.500   2  14   8  3.085   1   1    1    0    2  120    12   \n",
       "689   1  41.00   0.040   2  10   4  0.040   0   1    1    0    1  560     1   \n",
       "\n",
       "     Target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         1  \n",
       "4         1  \n",
       "..      ...  \n",
       "685       1  \n",
       "686       0  \n",
       "687       1  \n",
       "688       1  \n",
       "689       1  \n",
       "\n",
       "[690 rows x 15 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading data into pandas and renaming the columns:\n",
    "import pandas as pd \n",
    "credit_df = pd.read_csv('Australian.CSV',header=None,names=['A1','A2','A3','A4','A5','A6','A7','A8','A9','A10','A11','A12','A13','A14','Target'])\n",
    "credit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86ce0f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring category and continous DF's\n",
    "credit_df_cat=credit_df[['A1','A4','A5','A6','A8','A9','A11','A12','Target']]\n",
    "credit_df_cont=credit_df[['A2','A3','A7','A10','A13','A14','Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab5c55d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A7</th>\n",
       "      <th>A10</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.00000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31.568203</td>\n",
       "      <td>4.758725</td>\n",
       "      <td>2.223406</td>\n",
       "      <td>2.40000</td>\n",
       "      <td>184.014493</td>\n",
       "      <td>1018.385507</td>\n",
       "      <td>0.444928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.853273</td>\n",
       "      <td>4.978163</td>\n",
       "      <td>3.346513</td>\n",
       "      <td>4.86294</td>\n",
       "      <td>172.159274</td>\n",
       "      <td>5210.102598</td>\n",
       "      <td>0.497318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>13.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22.670000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.625000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.707500</td>\n",
       "      <td>7.207500</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>272.000000</td>\n",
       "      <td>396.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.250000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>67.00000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>100001.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               A2          A3          A7        A10          A13  \\\n",
       "count  690.000000  690.000000  690.000000  690.00000   690.000000   \n",
       "mean    31.568203    4.758725    2.223406    2.40000   184.014493   \n",
       "std     11.853273    4.978163    3.346513    4.86294   172.159274   \n",
       "min     13.750000    0.000000    0.000000    0.00000     0.000000   \n",
       "25%     22.670000    1.000000    0.165000    0.00000    80.000000   \n",
       "50%     28.625000    2.750000    1.000000    0.00000   160.000000   \n",
       "75%     37.707500    7.207500    2.625000    3.00000   272.000000   \n",
       "max     80.250000   28.000000   28.500000   67.00000  2000.000000   \n",
       "\n",
       "                 A14      Target  \n",
       "count     690.000000  690.000000  \n",
       "mean     1018.385507    0.444928  \n",
       "std      5210.102598    0.497318  \n",
       "min         1.000000    0.000000  \n",
       "25%         1.000000    0.000000  \n",
       "50%         6.000000    0.000000  \n",
       "75%       396.500000    1.000000  \n",
       "max    100001.000000    1.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_df_cont.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e114a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A1      690 non-null    int64  \n",
      " 1   A2      690 non-null    float64\n",
      " 2   A3      690 non-null    float64\n",
      " 3   A4      690 non-null    int64  \n",
      " 4   A5      690 non-null    int64  \n",
      " 5   A6      690 non-null    int64  \n",
      " 6   A7      690 non-null    float64\n",
      " 7   A8      690 non-null    int64  \n",
      " 8   A9      690 non-null    int64  \n",
      " 9   A10     690 non-null    int64  \n",
      " 10  A11     690 non-null    int64  \n",
      " 11  A12     690 non-null    int64  \n",
      " 12  A13     690 non-null    int64  \n",
      " 13  A14     690 non-null    int64  \n",
      " 14  Target  690 non-null    int64  \n",
      "dtypes: float64(3), int64(12)\n",
      "memory usage: 81.0 KB\n"
     ]
    }
   ],
   "source": [
    "credit_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c55741b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pregnancies</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Glucose</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BMI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DiabetesPedigreeFunction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Age</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BloodPressure</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SkinThickness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Insulin</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Feature  Ranking\n",
       "0               Pregnancies        1\n",
       "1                   Glucose        1\n",
       "5                       BMI        1\n",
       "6  DiabetesPedigreeFunction        1\n",
       "7                       Age        2\n",
       "2             BloodPressure        3\n",
       "3             SkinThickness        4\n",
       "4                   Insulin        5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE \n",
    "from sklearn.svm import SVR\n",
    "estimator = SVR(kernel=\"linear\")\n",
    "rfe = RFE(estimator,step=1)\n",
    "rfe = rfe.fit(X_train, y_train)\n",
    "rfe \n",
    "\n",
    "selected_rfe_features = pd.DataFrame({'Feature':list(X_train.columns),\n",
    "                                      'Ranking':rfe.ranking_})\n",
    "selected_rfe_features.sort_values(by='Ranking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a1e40cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = credit_df.drop('Target',axis=1)\n",
    "y =credit_df['Target']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train_scaler = sc.fit_transform(X_train)\n",
    "X_test_scaler = sc.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef515cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "483"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ecd49719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bfc0836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    383\n",
       "1    307\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the class ratio \n",
    "credit_df['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a55ae227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8502415458937198"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model= SVC(kernel = 'linear',C=1,gamma=100)\n",
    "model.fit(X_train_scaler,y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = model.predict(X_test_scaler)\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb96247",
   "metadata": {},
   "source": [
    "## 5.\tHow did the SVM model perform? Use a classification report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f668731d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.81      0.87       126\n",
      "           1       0.76      0.91      0.83        81\n",
      "\n",
      "    accuracy                           0.85       207\n",
      "   macro avg       0.85      0.86      0.85       207\n",
      "weighted avg       0.87      0.85      0.85       207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking model performance\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e912bda1",
   "metadata": {},
   "source": [
    "## 6.\tWhat kinds of jobs in data are you most interested in? Do some research on what is out there. Write about your thoughts in under 400 words. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fe0a84",
   "metadata": {},
   "source": [
    "There are a number of data jobs available in the market based on different experience levels.Jobs that match the skills I\n",
    "have learned would be of :\n",
    "   Data Analyst \n",
    "   Data Scientist\n",
    "   Data Engineer\n",
    "\n",
    "Some of the reason for my interest in these jobs are :\n",
    "    \n",
    "    1) Companies are Facing Real Challenges in Organizing Data so they need people who can understand and use \n",
    "      their data in an interesting way.\n",
    "    2) Great pay \n",
    "    3) Lot of scope for career advancement\n",
    "    4) Challenging day to day work that focuses on problem solving skills.\n",
    "    5) There are a plethora of other commonly-used job titles that involve data science work.Roles such as that \n",
    "    of a Data Scientist, Data Architect, BI Engineer, Business Analyst, Data Engineer, Database Administrator, \n",
    "    Data- and Analytics Manager are in high demand.\n",
    "    6)  Omnipresence of Jobs\n",
    "    \n",
    "I think I would be suitable for these jobs as I have a skill set similar to the requirement of these jobs and would be \n",
    "comfortable working with :\n",
    "    1) Intermediate data science programming in either Python or R, including the use of popular packages\n",
    "    2) Intermediate SQL queries\n",
    "    3) Data cleaning\n",
    "    4) Data visualization\n",
    "    5) Probability and statistics\n",
    "    6) Communicating complex data analysis clearly and understandably to people with no statistics \n",
    "    or programming background\n",
    "    \n",
    "I would also be interested in doing any kind of Data Science Internships as it would give me an on-the-job learning experience.\n",
    "Also, in many cases on-the-job learning often leads a path to a permanent, full-time job."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
